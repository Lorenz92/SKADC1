{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# !git clone 'https://github.com/Lorenz92/SKADC1.git'\n",
        "# % cd SKADC1\n",
        "# !echo $PWD"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import src.dataset as dataset\n",
        "import src.config as config \n",
        "from src.utils import *\n",
        "import src.models as models\n",
        "import src.losses as loss\n",
        "\n",
        "path = config.TRAIN_PATCHES_FOLDER\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(config.RANDOM_SEED)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7WwOlsifF-5G",
        "outputId": "303002ab-c8c4-4807-caeb-ee1c590d4326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  use_colab = True\n",
        "  print('Running on CoLab')\n",
        "else:\n",
        "  use_colab = False\n",
        "  print('Not running on CoLab')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if use_colab:\n",
        "    # Read file from Colab Notebook\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    config.MODEL_WEIGHTS = \"/content/drive/My Drive/Colab Notebooks/SKADC1\"\n",
        "    config.IMAGE_PATH = \"/content/drive/My Drive/Colab Notebooks/SKADC1/asset/560Mhz_1000h.fits\""
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Choose the feature extraction model\n",
        "# backbone='baseline_44'\n",
        "backbone='baseline_16'\n",
        "# backbone='vgg16'\n",
        "\n",
        "if backbone=='baseline_16':\n",
        "    # config.patch_dim = 50\n",
        "    config.patch_dim = 20\n",
        "    config.resizePatch = True\n",
        "    config.rpn_stride = 4\n",
        "    config.num_rois = 16\n",
        "    # anchors in the original image size\n",
        "    config.anchor_box_scales = [4, 8, 16, 24, 32, 64]\n",
        "    # config.anchor_box_scales = [6, 8, 12, 16, 24, 32, 64]\n",
        "    config.resizeFinalDim = 100\n",
        "    input_shape_1 = config.resizeFinalDim\n",
        "elif backbone=='baseline_44':\n",
        "    config.patch_dim = 20\n",
        "    config.resizePatch = True\n",
        "    config.rpn_stride = 8\n",
        "    config.num_rois = 16\n",
        "    # config.anchor_box_scales = [16,32,64] # anchors in the original image size\n",
        "    config.anchor_box_scales = [4, 8, 16, 24, 32, 64]\n",
        "    config.resizeFinalDim = 100\n",
        "    input_shape_1 = config.resizeFinalDim\n",
        "else:\n",
        "    config.patch_dim = 100\n",
        "    config.resizePatch = True\n",
        "    config.rpn_stride = 16\n",
        "    config.num_rois = 4\n",
        "    config.resizeFinalDim = 600\n",
        "    input_shape_1=config.resizeFinalDim\n",
        "    config.anchor_box_scales = [32, 64, 128]\n",
        "\n",
        "\n",
        "config.anchor_num = len(config.anchor_box_ratios)*len(config.anchor_box_scales)\n",
        "input_shape_2=(None, 4)\n",
        "\n",
        "print(config.resizePatch)\n",
        "print(config.rpn_stride)\n",
        "\n",
        "checkpoint = get_model_last_checkpoint(backbone)\n",
        "print(f'Model last checkpoint: {checkpoint}')\n",
        "\n",
        "file_path = f'{config.MODEL_WEIGHTS}/{backbone}'\n",
        "print(f'Writing configuration on txt file: {config.MODEL_WEIGHTS}/config.txt')\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "        \n",
        "f = open(f'{file_path}/config.txt',\"w+\")\n",
        "f.write(f'backbone = {backbone}\\n config.patch_dim = {config.patch_dim}\\n config.resizePatch = {config.resizePatch}\\n config.rpn_stride = {config.rpn_stride}\\n config.num_rois = {config.num_rois}\\n config.anchor_box_scales = {config.anchor_box_scales}\\n config.resizeFinalDim = {config.resizeFinalDim}\\n input_shape_1 = {input_shape_1}')\n",
        "f.close()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Dataset parsing and loading\n",
        "# use \"subset\" in config file to load a small portion of data for development/debugging purposes\n",
        "ska_dataset = dataset.SKADataset(k=3, print_info=False, show_plot=False, use_pb=False)"
      ],
      "outputs": [],
      "metadata": {
        "tags": [],
        "id": "Q8IbYCwkF-5K",
        "outputId": "5cd8e5ba-49cd-49b4-d65c-65d82229f792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.cleaned_train_df[['width', 'height', 'area_orig', 'area_cropped']].describe()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.cleaned_train_df[['width', 'height', 'area_orig']].quantile([.1,.2,.3,.4,.5,.6,.7,.8,.9,.95,.98,.99,1.])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "objects_to_ignore=[20167150, 27514971]\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "show_plot = True\n",
        "ska_dataset.generate_patches(limit=10, plot_patches=show_plot, objects_to_ignore=objects_to_ignore, source_dir=None, rgb_norm=True)\n",
        "# ska_dataset.generate_patches(limit=4000, plot_patches=show_plot, objects_to_ignore=objects_to_ignore, source_dir='./data/training/patches', rgb_norm=True)\n",
        "# ska_dataset.generate_patches(limit=1000, plot_patches=show_plot, objects_to_ignore=objects_to_ignore, source_dir='./data/training/patches', rgb_norm=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ug10Ku-OF-5Y",
        "outputId": "c3b6bed6-24a7-4f71-cbed-c4b6b8d934af",
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ska_dataset.analyze_class_distribution()"
      ],
      "outputs": [],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ska_dataset.split_train_val_stratified(random_state=42, val_portion=0.2)\n",
        "\n",
        "# print(len(ska_dataset.train_patch_list))\n",
        "# print(len(ska_dataset.val_patch_list))\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.split_train_val(random_state=42, val_portion=0.2, balanced=False)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## datagen + calc_rpn -> rpn_net -> rpn_to_roi -> calc_iou -> cls_net"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# print_img(config.TRAIN_PATCHES_FOLDER, '3_16406_16729_20', show_data=True)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# # Debugging\n",
        "\n",
        "# train_patch_list = ska_dataset.train_patch_list\n",
        "# patches_folder_path=config.TRAIN_PATCHES_FOLDER\n",
        "\n",
        "# train_datagen = prep.get_anchor_gt(patches_folder_path, ['20_16396_16729_20'], backbone, pixel_mean=None)\n",
        "# image, [y_rpn_cls_true, y_rpn_reg_true], img_data_aug, _, _, patch_id = next(train_datagen)\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get FRCNN model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rpn_model, detector_model, total_model = models.get_train_model(input_shape_1=input_shape_1, input_shape_2=input_shape_2, anchor_num=config.anchor_num, pooling_regions=config.pooling_regions, num_rois=config.num_rois, num_classes=len(ska_dataset.class_list)+1, backbone=backbone, use_expander=False)\n",
        "\n",
        "rpn_model.summary()\n",
        "detector_model.summary()\n",
        "total_model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load weights"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.class_list"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# checkpoint='0_frcnn_baseline_36.h5'\n",
        "models.load_weigths(rpn_model, detector_model, backbone, resume_train=False, checkpoint=checkpoint)\n",
        "models.compile_models(rpn_model, detector_model, total_model, rpn_losses=[loss.rpn_loss_cls, loss.rpn_loss_regr], detector_losses=[loss.detector_loss_cls, loss.detector_loss_regr], class_list=ska_dataset.class_list)\n",
        "# models.compile_models(rpn_model, detector_model, total_model, rpn_losses=[loss.rpn_loss_cls, loss.rpn_loss_regr], detector_losses=[loss.categorical_focal_loss([.25, .25, 0.05], 2.), loss.detector_loss_regr], class_list=ska_dataset.class_list)\n",
        "# models.compile_models(rpn_model, detector_model, total_model, rpn_losses=[loss.rpn_loss_cls, loss.rpn_loss_regr], detector_losses=[loss.categorical_focal_loss([2, 0.5, 2, 2, 0.05], 2.), loss.detector_loss_regr], class_list=ska_dataset.class_list)\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Specifically checking backbone weights\n",
        "\n",
        "# total_model.weights[24:25][0][0][0][0]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Check that all of the pretrained weights have been loaded.\n",
        "import numpy as np\n",
        "for i, j in zip(total_model.weights, rpn_model.weights): \n",
        "    # print(i,j)\n",
        "    assert np.allclose(i,j), 'Weights don\\'t match!'"
      ],
      "outputs": [],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- errore \"Exception: 'a' cannot be empty unless no samples are taken\" quando nel sampling ci sono meno di 4 roi\n",
        "- errore \"None type object is not iterable\" dovuto al max(IoUs) quando calc_iou torna None, None, None, None\n",
        "- patch di debug 1550_16376_16779_100\n",
        "- capire il parametro classifier_regr_std in che modo influenza il training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- provare normalizzazione valori immagini di input\n",
        "- provare a far passare più roi anzichè 4"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "len(ska_dataset.train_patch_list)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# In this cell we modify the image for debugging purposes\n",
        "\n",
        "# import cv2\n",
        "\n",
        "print_img(config.TRAIN_PATCHES_FOLDER, '2_16396_16729_20')\n",
        "### Flip image\n",
        "# img_aug = np.load(f'{config.TRAIN_PATCHES_FOLDER}/2_16396_16729_20/2_16396_16729_20.npy')\n",
        "# img_data_aug = pd.read_pickle(f'{config.TRAIN_PATCHES_FOLDER}/2_16396_16729_20/2_16396_16729_20.pkl')\n",
        "\n",
        "# rows, cols = img_aug.shape[:2]\n",
        "\n",
        "# img_aug = cv2.flip(img_aug, 0)\n",
        "# for index, row in img_data_aug.iterrows():\n",
        "#     y1 = row['y1s']\n",
        "#     y2 = row['y2s']\n",
        "#     img_data_aug.at[index,'y2s']= rows - y1\n",
        "#     img_data_aug.at[index,'y1s']= rows - y2\n",
        "\n",
        "# if not os.path.exists(f'{config.TRAIN_PATCHES_FOLDER}/2_16396_16729_20_aug/'):\n",
        "#     os.makedirs(f'{config.TRAIN_PATCHES_FOLDER}/2_16396_16729_20_aug/')\n",
        "\n",
        "# np.save((f'{config.TRAIN_PATCHES_FOLDER}/2_16396_16729_20_aug/2_16396_16729_20_aug.npy'), img_aug)\n",
        "# img_data_aug.to_pickle(f'{config.TRAIN_PATCHES_FOLDER}/2_16396_16729_20_aug/2_16396_16729_20_aug.pkl')\n",
        "\n",
        "# print_img(config.TRAIN_PATCHES_FOLDER, '2_16396_16729_20_aug')\n",
        "###\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from src.train import *\n",
        "\n",
        "val_patch_list = None\n",
        "train_frcnn(rpn_model, detector_model, total_model, ['2_16396_16729_20'], val_patch_list, ska_dataset.class_list, num_epochs=100, patches_folder_path=config.TRAIN_PATCHES_FOLDER, backbone=backbone, resume_train=True)\n",
        "# train_frcnn(rpn_model, detector_model, total_model, ska_dataset.train_patch_list, val_patch_list, ska_dataset.class_list, num_epochs=150, patches_folder_path=config.TRAIN_PATCHES_FOLDER, backbone=backbone, resume_train=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rpn_model_eval, detector_model_eval, total_model_eval = models.get_eval_model(input_shape_1=input_shape_1, input_shape_2=input_shape_2, input_shape_fmap=None, anchor_num=config.anchor_num, pooling_regions=config.pooling_regions, num_rois=config.num_rois, num_classes=len(ska_dataset.class_list)+1, backbone=backbone, use_expander=False)\n",
        "\n",
        "rpn_model_eval.summary()\n",
        "detector_model_eval.summary()\n",
        "total_model_eval.summary()"
      ],
      "outputs": [],
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Models used for mAP eval\n",
        "cp = '66_frcnn_baseline_44.h5'\n",
        "# cp = '0_frcnn_baseline_16.h5'\n",
        "models.load_weigths(rpn_model_eval, detector_model_eval, backbone, checkpoint=cp)\n",
        "models.compile_models(rpn_model_eval, detector_model_eval, total_model_eval, rpn_losses=[loss.rpn_loss_cls, loss.rpn_loss_regr], detector_losses=[loss.detector_loss_cls, loss.detector_loss_regr], class_list=ska_dataset.class_list)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "patch_id = ['2_16396_16729_20']\n",
        "# patch_id = ska_dataset.train_patch_list\n",
        "# print(patch_id)\n",
        "# gt = pd.read_pickle(f'{config.TRAIN_PATCHES_FOLDER}/{patch_id[0]}/{patch_id[0]}.pkl')\n",
        "# display(gt['class_label'])\n",
        "\n",
        "preds, mAP, prec, recall = evaluate_model(rpn_model_eval, detector_model_eval, backbone, patch_id, ska_dataset.class_list, metric_threshold=.5, acceptance_treshold=.5)"
      ],
      "outputs": [],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "preds"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(config.patch_dim , float(config.resizeFinalDim))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print_img(config.TRAIN_PATCHES_FOLDER, '5_16501_16729_50')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "anch = pd.read_pickle(f'{config.EVAL_RESULTS}/2_16396_16729_20/2_16396_16729_20.pkl')\n",
        "display(anch)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "anch['width'] = anch['x2s'] - anch['x1s']\n",
        "anch['heght'] = anch['y2s'] - anch['y1s']"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "anch.describe() "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print_img(config.TRAIN_PATCHES_FOLDER, '2_16396_16729_20', config.EVAL_RESULTS)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO - 20210508:\n",
        "- [X] troncamento rumore a 1e-6 tramite half gaussian\n",
        "\n",
        "TODO - 20210605:\n",
        "- [X] modificare RPNNet in modo che dia in output anche la backbone - Lorenzo\n",
        "- [X] scrivere bene training loop: salvare le loss in un df su disco + salvare pesi modello ad ogni giro (Lorenzo - finire di debuggare)\n",
        "\n",
        "TODO - 20210620:\n",
        "- [x] implementare mAP in una funzione che prende come parametro un modello o i suoi pesi\n",
        "- [x] implementare resNet50\n",
        "- [x] implementare predicted rois - Lorenzo\n",
        "- [X] implementare plot loss training - Lorenzo\n",
        "- [X] finire classe datasetv2 - Alice\n",
        "- [X] check se su colab le performance sono migliori - Lorenzo\n",
        "\n",
        "TODO - 20210627\n",
        "- [X] split dataset su combinazioni classi - Alice\n",
        "- [x] provare campionamento random patch ed osservare le due distribuzioni - Alice\n",
        "\n",
        "TODO - 20210703\n",
        "- [x] sistemare salvataggio loss training loop - Lorenzo\n",
        "- [x] Riscalare immagini tra 0-255 - Alice\n",
        "- [x] capire se passare tre immagini diverse come input\n",
        "- [x] usare media vgg16 per zero-centering - Alice\n",
        "\n",
        "TODO - 20210705\n",
        "- [x] sistemare nomi funzioni dataset per trasformazione rgb\n",
        "\n",
        "TODO - 20210711\n",
        "- [x] rifattorizzare classe dataset spostando nel costruttore i metodi che calcolano i suoi attributi - Lorenzo\n",
        "- [x] chek valori pixel in input per resnet\n",
        "- [x] fare funzione per plottare le predictions\n",
        "- [ ] trainare tutto su colab\n",
        "\n",
        "TODO - 20210714\n",
        "- [x] ragionare su come scalare le immagini fra 0 e 1, attualmente hanno tanti valori schiacciati a 0 e il massimo su tutto il train a a 0.4\n",
        "\n",
        "TODO - 20210717\n",
        "- [ ] Ablation study: provare a rimuovere stage4 nella resnet - se c'è tempo\n",
        "- [x] Provare con nostra pixel_mean e con vgg16 pixel_mean -> per il momento abbiamo scartato la prima opzione\n",
        "- [x] Fare qualche analisi di distribuzione delle classi/dim box del dataset - Alice\n",
        "- [x] Aggiungere normalizzazione dopo zero centering per resNet50, sulla base del range globale dell'immagine di training\n",
        "- [x] Provare pulizia dataset originale sulla base del rumore/flusso - Alice\n",
        "- [ ] Cambiare nomi di tutto - alla fine\n",
        "- [x] implementare zero-centering su volare medio RGB delle nostre patch\n",
        "- [x] Funzione che trova l'ultimo checkpoint in colab prima del load_weights - Lorenzo\n",
        "\n",
        "TODO - 20210801\n",
        "- [x] Debuggare training baseline 8 e 16 - L\n",
        "- [x] Finire prove pulizia dataseet noise variando k - A\n",
        "\n",
        "TODO - 20210904\n",
        "- [ ] Provare NMS per rimuovere oggetti crowded\n",
        "- [ ] In evaluate model eliminare le box con una delle due dim a 0 e quelle che escono dalla patch"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Summary\n",
        "    - riassunto progetto\n",
        "2.  Background\n",
        "    - SoTA + teoria di base\n",
        "3.  System Description\n",
        "    - descrizione dei nostri modelli e dei loro componenti (moduli)\n",
        "4.  Experimental setup and results\n",
        "    - dataset pre processing\n",
        "    - training environment\n",
        "    - metrics\n",
        "    - results\n",
        "5.  Results and error analysis\n",
        "6.  Discussion"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "loss_history = np.load(f\"./model/{backbone}/loss_history.npy\")\n",
        "print(loss_history.shape)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "loss_history"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_loss(loss_history[:])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "loss_history[:,1].shape"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.convolve(loss_history[1], np.ones(10), 'valid') / 10"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n",
        "\n",
        "lsma_0 = moving_average(loss_history[100:,2], 200)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, len(lsma_0)), lsma_0, 'r')\n",
        "plt.title('rpn cls')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelli da trainare:\n",
        "epoch lenght = 200\n",
        "- baseline_16: patch 50 -> 100, [8,16,32,64]-[1:1], 16roi, limit=4000, 10k epoche, focal_loss, norm: /255, no bilanciamento dataset, rgbNorm=True - A\n",
        "- baseline_16: patch 50 -> 100, [8,16,32,64]-[1:1], 16roi, limit=4000, 10k epoche, NO focal_loss, norm: /255, no bilanciamento dataset, rgbNorm=True - A\n",
        "\n",
        "- baseline_16: patch 20->100,  [8,16,32,64]-[1:1,1:2,2:1], 16roi, limit=4000, 10k epoche, focal_loss, norm: /255, no bilanciamento dataset, rgbNorm=True - L\n",
        "- baseline_16: patch 20->100,  [8,16,32,64]-[1:1,1:2,2:1], 16roi, limit=4000, 10k epoche, focal_loss, norm: /255, no bilanciamento dataset, rgbNorm=True, layer 3 e 4 trainabili - L\n",
        "\n",
        "- baseline_16: patch 100->100,  [8,16,32,64]-[1:1,1:2,2:1], 16roi, limit=4000, 10k epoche, focal_loss, norm: /255, no bilanciamento dataset, rgbNorm=True\n",
        "\n",
        "- vgg16: 100 -> 600, [32,64,128,256,512]-[1:1,1:2,2:1], 16roi, limit=4000, 10k epoche, focal_loss, norm: /255, no bilanciamento dataset, rgbNorm=True"
      ],
      "metadata": {}
    }
  ]
}