@inproceedings{cheng2018revisiting,
  title={Revisiting rcnn: On awakening the classification power of faster rcnn},
  author={Cheng, Bowen and Wei, Yunchao and Shi, Honghui and Feris, Rogerio and Xiong, Jinjun and Huang, Thomas},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={453--468},
  year={2018}
}

@misc{faster-rcnn,
      title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 
      author={Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun},
      year={2016},
      eprint={1506.01497},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yolo,
      title={You Only Look Once: Unified, Real-Time Object Detection}, 
      author={Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
      year={2016},
      eprint={1506.02640},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{ssd,
   title={SSD: Single Shot MultiBox Detector},
   ISBN={9783319464480},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-319-46448-0_2},
   DOI={10.1007/978-3-319-46448-0_2},
   journal={Lecture Notes in Computer Science},
   publisher={Springer International Publishing},
   author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
   year={2016},
   pages={21–37}
}

@misc{cnn-features,
      title={Visualizing and Understanding Convolutional Networks}, 
      author={Matthew D Zeiler and Rob Fergus},
      year={2013},
      eprint={1311.2901},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{transfer-learning-1,
author = {Talukdar, Jonti and Gupta, S. and Rajpura, P. and Hegde, Ravi},
year = {2018},
month = {02},
pages = {78-83},
title = {Transfer Learning for Object Detection using State-of-the-Art Deep Neural Networks},
doi = {10.1109/SPIN.2018.8474198}
}

@inproceedings{transfer-learning-2,
title={Pay Attention to Features, Transfer Learn Faster CNNs},
author={Kafeng Wang and Xitong Gao and Yiren Zhao and Xingjian Li and Dejing Dou and Cheng-Zhong Xu},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=ryxyCeHtPB}
}

@article{claran,
    author = {Wu, Chen and Wong, Oiwei Ivy and Rudnick, Lawrence and Shabala, Stanislav S and Alger, Matthew J and Banfield, Julie K and Ong, Cheng Soon and White, Sarah V and Garon, Avery F and Norris, Ray P and Andernach, Heinz and Tate, Jean and Lukic, Vesna and Tang, Hongming and Schawinski, Kevin and Diakogiannis, Foivos I},
    title = "{Radio Galaxy Zoo: Claran – a deep learning classifier for radio morphologies}",
    journal = {Monthly Notices of the Royal Astronomical Society},
    volume = {482},
    number = {1},
    pages = {1211-1230},
    year = {2018},
    month = {10},
    abstract = "{The upcoming next-generation large area radio continuum surveys can expect tens of millions of radio sources, rendering the traditional method for radio morphology classification through visual inspection unfeasible. We present Claran — Classifying Radio sources Automatically with Neural networks — a proof-of-concept radio source morphology classifier based upon the Faster Region-based Convolutional Neutral Networks method. Specifically, we train and test Claran on the FIRST and WISE (Wide-field Infrared Survey Explorer) images from the Radio Galaxy Zoo Data Release 1 catalogue. Claran provides end users with automated identification of radio source morphology classifications from a simple input of a radio image and a counterpart infrared image of the same region. Claran is the first open-source, end-to-end radio source morphology classifier that is capable of locating and associating discrete and extended components of radio sources in a fast (\\&lt;200 ms per image) and accurate (≥90 per cent) fashion. Future work will improve Claran’s relatively lower success rates in dealing with multisource fields and will enable Claran to identify sources on much larger fields without loss in classification accuracy.}",
    issn = {0035-8711},
    doi = {10.1093/mnras/sty2646},
    url = {https://doi.org/10.1093/mnras/sty2646},
    eprint = {https://academic.oup.com/mnras/article-pdf/482/1/1211/26205089/sty2646.pdf},
}

@misc{rcnn,
      title={Rich feature hierarchies for accurate object detection and semantic segmentation}, 
      author={Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
      year={2014},
      eprint={1311.2524},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{fast-rcnn,
      title={Fast R-CNN}, 
      author={Ross Girshick},
      year={2015},
      eprint={1504.08083},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{mask-rcnn,
      title={Mask R-CNN}, 
      author={Kaiming He and Georgia Gkioxari and Piotr Dollár and Ross Girshick},
      year={2018},
      eprint={1703.06870},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{bonaldi2021square,
  title={Square Kilometre Array Science Data Challenge 1: analysis and results},
  author={Bonaldi, A and An, T and Br{\"u}ggen, M and Burkutean, S and Coelho, B and Goodarzi, H and Hartley, P and Sandhu, PK and Wu, C and Yu, L and others},
  journal={Monthly Notices of the Royal Astronomical Society},
  volume={500},
  number={3},
  pages={3821--3837},
  year={2021},
  publisher={Oxford University Press}
}

@online{ska-site,
  author = {SKA},
  title  = {SKA web site},
  url    = {https://www.skatelescope.org/news/ska-launches-science-data-challenge/}
}

@article{huber-loss,
author = {Peter J. Huber},
title = {{Robust Estimation of a Location Parameter}},
volume = {35},
journal = {The Annals of Mathematical Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {73 -- 101},
year = {1964},
doi = {10.1214/aoms/1177703732},
URL = {https://doi.org/10.1214/aoms/1177703732}
}


@online{nms,
  author = {Kaushik Patnaik},
  title  = {Non Maximum Suppression},
  url    = {https://paperswithcode.com/method/non-maximum-suppression}
}

@misc{iou,
      title={Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression}, 
      author={Hamid Rezatofighi and Nathan Tsoi and JunYoung Gwak and Amir Sadeghian and Ian Reid and Silvio Savarese},
      year={2019},
      eprint={1902.09630},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}



@misc{focal-loss,
      title={Focal Loss for Dense Object Detection}, 
      author={Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Dollár},
      year={2018},
      eprint={1708.02002},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url=https://arxiv.org/abs/1708.02002
}

@misc{vgg,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@online{colab,
  author = {Google},
  title  = {Colaboratory},
  url    = {https://colab.research.google.com/}
}


@online{roi-pooling,
  author = {Kaushik Patnaik},
  title  = {Annotated RPN, ROI Pooling and ROI Align},
  url    = {https://kaushikpatnaik.github.io/annotated/papers/2020/07/04/ROI-Pool-and-Align-Pytorch-Implementation.html}
}

@online{keras,
  title={Keras},
  author={Chollet, Francois and others},
  year={2015},
  publisher={GitHub},
  url={https://github.com/fchollet/keras},
}

@misc{tensorflow,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@misc{fpn,
      title={Feature Pyramid Networks for Object Detection}, 
      author={Tsung-Yi Lin and Piotr Dollár and Ross Girshick and Kaiming He and Bharath Hariharan and Serge Belongie},
      year={2017},
      eprint={1612.03144},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{frcnn-small-obj,
author = {Cao, Changqing and Wang, Bo and Zhang, Wenrui and Zeng, Xiaodong and Yan, Xu and Feng, Zhejun and Liu, Yutao and Wu, Zengyan},
year = {2019},
month = {08},
pages = {1-1},
title = {An Improved Faster R-CNN for Small Object Detection},
volume = {7},
journal = {IEEE Access},
doi = {10.1109/ACCESS.2019.2932731}
}

@misc{effective-rf,
      title={Understanding the Effective Receptive Field in Deep Convolutional Neural Networks}, 
      author={Wenjie Luo and Yujia Li and Raquel Urtasun and Richard Zemel},
      year={2017},
      eprint={1701.04128},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{warm-up,
      title={Bag of Freebies for Training Object Detection Neural Networks}, 
      author={Zhi Zhang and Tong He and Hang Zhang and Zhongyue Zhang and Junyuan Xie and Mu Li},
      year={2019},
      eprint={1902.04103},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}