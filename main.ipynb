{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# !git clone 'https://github.com/Lorenz92/SKADC1.git'\n",
        "# % cd SKADC1\n",
        "# !echo $PWD\n",
        "# !pip install requirements.txt"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "\n",
        "import src.dataset as dataset\n",
        "import src.config as config \n",
        "from src.utils import *\n",
        "import src.models as models\n",
        "import src.losses as loss\n",
        "\n",
        "path = config.TRAIN_PATCHES_FOLDER\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(config.RANDOM_SEED)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7WwOlsifF-5G",
        "outputId": "303002ab-c8c4-4807-caeb-ee1c590d4326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  use_colab = True\n",
        "  print('Running on CoLab')\n",
        "else:\n",
        "  use_colab = False\n",
        "  print('Not running on CoLab')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "source_dir = './data/training/patches'\n",
        "\n",
        "if use_colab:\n",
        "    # Read file from Colab Notebook\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    config.MODEL_WEIGHTS = \"/content/drive/My Drive/Colab Notebooks/SKADC1\"\n",
        "    config.IMAGE_PATH = \"/content/drive/My Drive/Colab Notebooks/SKADC1/asset/560Mhz_1000h.fits\"\n",
        "    config.TRAIN_DATA_FOLDER = \"/content/drive/My Drive/Colab Notebooks/SKADC1/asset\"\n",
        "    config.TRAIN_PATCHES_FOLDER = \"/content/drive/My Drive/Colab Notebooks/SKADC1/patches\"\n",
        "    source_dir = \"/content/drive/My Drive/Colab Notebooks/SKADC1/asset/patches\""
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Choose the feature extraction model\n",
        "backbone='baseline_44'\n",
        "# backbone='baseline_16'\n",
        "# backbone='vgg16'\n",
        "\n",
        "if backbone=='baseline_16':\n",
        "    config.patch_dim = 20\n",
        "    config.resizePatch = True\n",
        "    config.rpn_stride = 4\n",
        "    config.num_rois = 16\n",
        "    config.anchor_box_scales = [4, 8, 16, 24, 32, 64] # anchors in the original image size\n",
        "    config.resizeFinalDim = 100\n",
        "    input_shape_1 = config.resizeFinalDim\n",
        "elif backbone=='baseline_44':\n",
        "    config.patch_dim = 20\n",
        "    config.resizePatch = True\n",
        "    config.rpn_stride = 8\n",
        "    config.num_rois = 16\n",
        "    config.anchor_box_scales = [4, 8, 16, 24, 32, 64]\n",
        "    config.resizeFinalDim = 100\n",
        "    input_shape_1 = config.resizeFinalDim\n",
        "else:\n",
        "    config.patch_dim = 100\n",
        "    config.resizePatch = True\n",
        "    config.rpn_stride = 16\n",
        "    config.num_rois = 16\n",
        "    config.resizeFinalDim = 600\n",
        "    input_shape_1=config.resizeFinalDim\n",
        "    config.anchor_box_scales = [32,64,128]\n",
        "    config.in_out_img_size_ratio = config.rpn_stride\n",
        "\n",
        "config.anchor_num = len(config.anchor_box_ratios)*len(config.anchor_box_scales)\n",
        "input_shape_2=(None, 4)\n",
        "use_focal_loss = False\n",
        "\n",
        "checkpoint = get_model_last_checkpoint(backbone)\n",
        "print(f'Model last checkpoint: {checkpoint}')\n",
        "\n",
        "file_path = f'{config.MODEL_WEIGHTS}/{backbone}'\n",
        "print(f'Writing configuration on txt file: {config.MODEL_WEIGHTS}/config.txt')\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "        \n",
        "f = open(f'{file_path}/config.txt',\"w+\")\n",
        "f.write(f'backbone = {backbone}\\n config.patch_dim = {config.patch_dim}\\n config.resizePatch = {config.resizePatch}\\n config.rpn_stride = {config.rpn_stride}\\n config.num_rois = {config.num_rois}\\n config.anchor_box_scales = {config.anchor_box_scales}\\n config.resizeFinalDim = {config.resizeFinalDim}\\n input_shape_1 = {input_shape_1}')\n",
        "f.close()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Dataset parsing and loading\n",
        "# use \"subset\" in config file to load a small portion of data for development/debugging purposes\n",
        "ska_dataset = dataset.SKADataset(print_info=False, show_plot=True)"
      ],
      "outputs": [],
      "metadata": {
        "tags": [],
        "id": "Q8IbYCwkF-5K",
        "outputId": "5cd8e5ba-49cd-49b4-d65c-65d82229f792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.cleaned_train_df[['width', 'height', 'area_orig', 'area_cropped']].describe()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.cleaned_train_df[['width', 'height', 'area_orig']].quantile([.1,.2,.3,.4,.5,.6,.7,.8,.9,.95,.98,.99,1.])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "objects_to_ignore=[20167150, 27514971]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.generate_patches(limit=10000, plot_patches=False, objects_to_ignore=objects_to_ignore, source_dir=source_dir, rgb_norm=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ug10Ku-OF-5Y",
        "outputId": "c3b6bed6-24a7-4f71-cbed-c4b6b8d934af",
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Use seed=5 for 20_100 set and seed=15 for 50_100\n",
        "ska_dataset.split_train_val(random_state=5, val_portion=0.2, balanced=False, size=350)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get FRCNN model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rpn_model, detector_model, total_model = models.get_train_model(input_shape_1=input_shape_1, input_shape_2=input_shape_2, anchor_num=config.anchor_num, pooling_regions=config.pooling_regions, num_rois=config.num_rois, num_classes=len(ska_dataset.class_list)+1, backbone=backbone, use_expander=False)\n",
        "\n",
        "rpn_model.summary()\n",
        "detector_model.summary()\n",
        "total_model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load weights"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "checkpoint= 'loss_0_frcnn_baseline_16.h5'\n",
        "models.load_weigths(rpn_model, detector_model, backbone, resume_train=True, checkpoint=checkpoint)\n",
        "\n",
        "if use_focal_loss:\n",
        "    models.compile_models(rpn_model, detector_model, total_model, rpn_losses=[loss.rpn_loss_cls, loss.rpn_loss_regr], detector_losses=[loss.categorical_focal_loss(config.alpha, config.gamma), loss.detector_loss_regr], class_list=ska_dataset.class_list)\n",
        "else:\n",
        "    models.compile_models(rpn_model, detector_model, total_model, rpn_losses=[loss.rpn_loss_cls, loss.rpn_loss_regr], detector_losses=[loss.detector_loss_cls, loss.detector_loss_regr], class_list=ska_dataset.class_list)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# If you want to specifically check backbone weights you need to slice weights tensors like this:\n",
        "# total_model.weights[24:25][0][0][0][0]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Check that all of the pretrained weights have been loaded.\n",
        "import numpy as np\n",
        "for i, j in zip(total_model.weights, rpn_model.weights): \n",
        "    assert np.allclose(i,j), 'Weights don\\'t match!'"
      ],
      "outputs": [],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Generating validation model for validation step at epoch's end\n",
        "rpn_model_eval, detector_model_eval, total_model_eval = models.get_eval_model(input_shape_1=input_shape_1, input_shape_2=input_shape_2, input_shape_fmap=None, anchor_num=config.anchor_num, pooling_regions=config.pooling_regions, num_rois=config.num_rois, num_classes=len(ska_dataset.class_list)+1, backbone=backbone, use_expander=False)\n",
        "\n",
        "rpn_model_eval.summary()\n",
        "detector_model_eval.summary()\n",
        "total_model_eval.summary()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from src.train import *\n",
        "\n",
        "train_frcnn(rpn_model, detector_model, total_model, ska_dataset.train_patch_list, rpn_model_eval, detector_model_eval, total_model_eval, ska_dataset.val_patch_list, ska_dataset.class_list, num_epochs=30, patches_folder_path=config.TRAIN_PATCHES_FOLDER, backbone=backbone, resume_train=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rpn_model_eval, detector_model_eval, total_model_eval = models.get_eval_model(input_shape_1=input_shape_1, input_shape_2=input_shape_2, input_shape_fmap=None, anchor_num=config.anchor_num, pooling_regions=config.pooling_regions, num_rois=config.num_rois, num_classes=len(ska_dataset.class_list)+1, backbone=backbone, use_expander=False)\n",
        "\n",
        "rpn_model_eval.summary()\n",
        "detector_model_eval.summary()\n",
        "total_model_eval.summary()"
      ],
      "outputs": [],
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell please select weights to be used to perform model evaluation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cp = 'map_63_frcnn_baseline_44.h5'"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Models used for mAP eval\n",
        "models.load_weigths(rpn_model_eval, detector_model_eval, backbone, checkpoint=cp)\n",
        "models.compile_models(rpn_model_eval, detector_model_eval, total_model_eval, rpn_losses=[loss.rpn_loss_cls, loss.rpn_loss_regr], detector_losses=[loss.detector_loss_cls, loss.detector_loss_regr], class_list=ska_dataset.class_list)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluation step carried out on the entire validation set\n",
        "\n",
        "preds, mAP, mPrecision, mRecall = evaluate_model(rpn_model_eval, detector_model_eval, backbone, ska_dataset.val_patch_list, ska_dataset.class_list, map_threshold=.5, acceptance_treshold=.5, save_eval_results=False)"
      ],
      "outputs": [],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "preds, mAP, mPrecision, mRecall = evaluate_model(rpn_model_eval, detector_model_eval, backbone, ska_dataset.train_patch_list, ska_dataset.class_list, map_threshold=.5, acceptance_treshold=.5, save_eval_results=False)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Qualitative evaluation by printing image, ground truth and predicted bounding boxes\n",
        "\n",
        "patch = '92_17296_16729_20'\n",
        "\n",
        "print_img(config.TRAIN_PATCHES_FOLDER, patch, config.EVAL_RESULTS, show_data=False)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss plot"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "loss_history = np.load(f\"./model/{backbone}/loss_history.npy\")\n",
        "print(loss_history.shape)\n",
        "plot_loss(loss_history[:])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation metrics plot"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "scores_history = np.load(f\"./model/{backbone}/scores_history.npy\")\n",
        "print(scores_history.shape)\n",
        "plot_scores(scores_history[:])\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "lsma_0 = moving_average(loss_history[100:,2], 200)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, len(lsma_0)), lsma_0, 'r')\n",
        "plt.title('rpn cls')\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ]
}