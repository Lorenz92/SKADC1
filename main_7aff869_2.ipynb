{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# !git clone -b retry_rgb_norm 'https://github.com/Lorenz92/SKADC1.git'\n",
        "# % cd SKADC1\n",
        "# !echo $PWD\n",
        "# !pip install tensorflow==2.4.1 keras==2.4.3 pandas==1.2.2"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import src.dataset as dataset\n",
        "import src.config as config \n",
        "from src.utils import *\n",
        "import src.models as models\n",
        "import src.losses as loss\n",
        "\n",
        "path = config.TRAIN_PATCHES_FOLDER\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(config.RANDOM_SEED)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "metadata": {
        "id": "7WwOlsifF-5G",
        "outputId": "303002ab-c8c4-4807-caeb-ee1c590d4326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  use_colab = True\n",
        "  print('Running on CoLab')\n",
        "else:\n",
        "  use_colab = False\n",
        "  print('Not running on CoLab')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "source_dir = './data/training/patches'\n",
        "\n",
        "if use_colab:\n",
        "    # Read file from Colab Notebook\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    config.MODEL_WEIGHTS = \"/content/drive/My Drive/Colab Notebooks/SKADC1\"\n",
        "    config.IMAGE_PATH = \"/content/drive/My Drive/Colab Notebooks/SKADC1/asset/560Mhz_1000h.fits\"\n",
        "    config.TRAIN_DATA_FOLDER = \"/content/drive/My Drive/Colab Notebooks/SKADC1/asset\"\n",
        "    config.TRAIN_PATCHES_FOLDER = \"/content/drive/My Drive/Colab Notebooks/SKADC1/patches\"\n",
        "    source_dir = \"/content/drive/My Drive/Colab Notebooks/SKADC1/asset/patches\""
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# Choose the feature extraction model\n",
        "# backbone='baseline_44'\n",
        "backbone='baseline_16'\n",
        "# backbone='vgg16'\n",
        "\n",
        "if backbone=='baseline_16':\n",
        "    # config.patch_dim = 50\n",
        "    config.patch_dim = 20\n",
        "    config.resizePatch = True\n",
        "    config.rpn_stride = 4\n",
        "    config.num_rois = 16\n",
        "    # anchors in the original image size\n",
        "    config.anchor_box_scales = [4, 8, 16, 24, 32, 64]\n",
        "    # config.anchor_box_scales = [6, 8, 12, 16, 24, 32, 64]\n",
        "    config.resizeFinalDim = 100\n",
        "    input_shape_1 = config.resizeFinalDim\n",
        "elif backbone=='baseline_44':\n",
        "    config.patch_dim = 20\n",
        "    config.resizePatch = True\n",
        "    config.rpn_stride = 8\n",
        "    config.num_rois = 16\n",
        "    # config.anchor_box_scales = [16,32,64] # anchors in the original image size\n",
        "    config.anchor_box_scales = [4, 8, 16, 24, 32, 64]\n",
        "    config.resizeFinalDim = 100\n",
        "    input_shape_1 = config.resizeFinalDim\n",
        "else:\n",
        "    config.patch_dim = 100\n",
        "    config.resizePatch = True\n",
        "    config.rpn_stride = 16\n",
        "    config.num_rois = 16\n",
        "    config.resizeFinalDim = 600\n",
        "    input_shape_1=config.resizeFinalDim\n",
        "    config.anchor_box_scales = [32,64,128]\n",
        "    config.in_out_img_size_ratio = config.rpn_stride\n",
        "\n",
        "\n",
        "\n",
        "config.anchor_num = len(config.anchor_box_ratios)*len(config.anchor_box_scales)\n",
        "input_shape_2=(None, 4)\n",
        "\n",
        "print(config.resizePatch)\n",
        "print(config.rpn_stride)\n",
        "\n",
        "checkpoint = get_model_last_checkpoint(backbone)\n",
        "print(f'Model last checkpoint: {checkpoint}')\n",
        "\n",
        "file_path = f'{config.MODEL_WEIGHTS}/{backbone}'\n",
        "print(f'Writing configuration on txt file: {config.MODEL_WEIGHTS}/config.txt')\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "        \n",
        "f = open(f'{file_path}/config.txt',\"w+\")\n",
        "f.write(f'backbone = {backbone}\\n config.patch_dim = {config.patch_dim}\\n config.resizePatch = {config.resizePatch}\\n config.rpn_stride = {config.rpn_stride}\\n config.num_rois = {config.num_rois}\\n config.anchor_box_scales = {config.anchor_box_scales}\\n config.resizeFinalDim = {config.resizeFinalDim}\\n input_shape_1 = {input_shape_1}')\n",
        "f.close()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "4\n",
            "Checking model checkpoints in directory /Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/map_2_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/map_8_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_26_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_4_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_14_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_1_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/map_9_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_5_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_10_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_28_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_0_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_77_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_2_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_17_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_59_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_20_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/loss_8_frcnn_baseline_16.h5\n",
            "/Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/baseline_16/map_1_frcnn_baseline_16.h5\n",
            "Model last checkpoint: loss_77_frcnn_baseline_16.h5\n",
            "Writing configuration on txt file: /Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/model/config.txt\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# Dataset parsing and loading\n",
        "# use \"subset\" in config file to load a small portion of data for development/debugging purposes\n",
        "ska_dataset = dataset.SKADataset(k=3, print_info=False, show_plot=False, use_pb=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (19222, 15)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>RA (core)</th>\n",
              "      <th>DEC (core)</th>\n",
              "      <th>RA (centroid)</th>\n",
              "      <th>DEC (centroid)</th>\n",
              "      <th>FLUX</th>\n",
              "      <th>Core frac</th>\n",
              "      <th>BMAJ</th>\n",
              "      <th>BMIN</th>\n",
              "      <th>PA</th>\n",
              "      <th>SIZE</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>SELECTION</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24121695</td>\n",
              "      <td>-0.642227</td>\n",
              "      <td>-29.775242</td>\n",
              "      <td>-0.642316</td>\n",
              "      <td>-29.775211</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.600</td>\n",
              "      <td>5.551</td>\n",
              "      <td>328.554</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19704.519</td>\n",
              "      <td>17712.942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20167150</td>\n",
              "      <td>-0.390473</td>\n",
              "      <td>-29.867493</td>\n",
              "      <td>-0.390667</td>\n",
              "      <td>-29.868851</td>\n",
              "      <td>0.029555</td>\n",
              "      <td>0.016924</td>\n",
              "      <td>107.110</td>\n",
              "      <td>43.263</td>\n",
              "      <td>191.258</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18401.338</td>\n",
              "      <td>17160.919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20045120</td>\n",
              "      <td>-0.021411</td>\n",
              "      <td>-29.643486</td>\n",
              "      <td>-0.021359</td>\n",
              "      <td>-29.643561</td>\n",
              "      <td>0.000653</td>\n",
              "      <td>0.012185</td>\n",
              "      <td>5.037</td>\n",
              "      <td>3.525</td>\n",
              "      <td>276.587</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16493.600</td>\n",
              "      <td>18506.577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33938384</td>\n",
              "      <td>-0.316375</td>\n",
              "      <td>-29.697647</td>\n",
              "      <td>-0.316375</td>\n",
              "      <td>-29.697647</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.266</td>\n",
              "      <td>346.641</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18020.319</td>\n",
              "      <td>18182.095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7527248</td>\n",
              "      <td>-0.336528</td>\n",
              "      <td>-29.627335</td>\n",
              "      <td>-0.336527</td>\n",
              "      <td>-29.627338</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.044763</td>\n",
              "      <td>3.343</td>\n",
              "      <td>1.515</td>\n",
              "      <td>279.006</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18125.824</td>\n",
              "      <td>18600.680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  RA (core)  DEC (core)  RA (centroid)  DEC (centroid)      FLUX  \\\n",
              "0  24121695  -0.642227  -29.775242      -0.642316      -29.775211  0.000035   \n",
              "1  20167150  -0.390473  -29.867493      -0.390667      -29.868851  0.029555   \n",
              "2  20045120  -0.021411  -29.643486      -0.021359      -29.643561  0.000653   \n",
              "3  33938384  -0.316375  -29.697647      -0.316375      -29.697647  0.000017   \n",
              "4   7527248  -0.336528  -29.627335      -0.336527      -29.627338  0.000054   \n",
              "\n",
              "   Core frac     BMAJ    BMIN       PA  SIZE  CLASS  SELECTION          x  \\\n",
              "0   0.000000    5.600   5.551  328.554     1      1          1  19704.519   \n",
              "1   0.016924  107.110  43.263  191.258     1      1          1  18401.338   \n",
              "2   0.012185    5.037   3.525  276.587     1      1          1  16493.600   \n",
              "3   0.000000    0.847   0.266  346.641     2      1          1  18020.319   \n",
              "4   0.044763    3.343   1.515  279.006     1      1          1  18125.824   \n",
              "\n",
              "           y  \n",
              "0  17712.942  \n",
              "1  17160.919  \n",
              "2  18506.577  \n",
              "3  18182.095  \n",
              "4  18600.680  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: VerifyWarning: Invalid 'BLANK' keyword in header.  The 'BLANK' keyword is only applicable to integer data, and will be ignored in this HDU. [astropy.io.fits.hdu.image]\n",
            "  0%|          | 0/19222 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading FITS file /Users/lorenzocellini/AI - Universit…/Deep Learning - Andre Asperti/SKA_project/SKADC1/data/training/560Mhz_1000h.fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19222/19222 [00:02<00:00, 6901.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (19222, 15)\n",
            "Found 0 boxes with zero area\n",
            "Rows to be deleted: 0\n",
            "New dataset shape: (19222, 15)\n",
            "Extending dataset with new computed columns...\n",
            "Final cleaned dataset shape: (19222, 26)\n",
            "\n",
            "Enlarging bboxes...\n",
            "DONE - Enlarging bboxes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>RA (core)</th>\n",
              "      <th>DEC (core)</th>\n",
              "      <th>RA (centroid)</th>\n",
              "      <th>DEC (centroid)</th>\n",
              "      <th>FLUX</th>\n",
              "      <th>Core frac</th>\n",
              "      <th>BMAJ</th>\n",
              "      <th>BMIN</th>\n",
              "      <th>PA</th>\n",
              "      <th>...</th>\n",
              "      <th>x2</th>\n",
              "      <th>y2</th>\n",
              "      <th>major_semia_px</th>\n",
              "      <th>minor_semia_px</th>\n",
              "      <th>pa_in_rad</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>area_orig</th>\n",
              "      <th>area_cropped</th>\n",
              "      <th>class_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24121695</td>\n",
              "      <td>-0.642227</td>\n",
              "      <td>-29.775242</td>\n",
              "      <td>-0.642316</td>\n",
              "      <td>-29.775211</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.600</td>\n",
              "      <td>5.551</td>\n",
              "      <td>328.554</td>\n",
              "      <td>...</td>\n",
              "      <td>19710.764566</td>\n",
              "      <td>17719.170105</td>\n",
              "      <td>6.264429</td>\n",
              "      <td>6.218255</td>\n",
              "      <td>5.734349</td>\n",
              "      <td>12.503792</td>\n",
              "      <td>12.461712</td>\n",
              "      <td>155.818657</td>\n",
              "      <td>155.818657</td>\n",
              "      <td>1_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20167150</td>\n",
              "      <td>-0.390473</td>\n",
              "      <td>-29.867493</td>\n",
              "      <td>-0.390667</td>\n",
              "      <td>-29.868851</td>\n",
              "      <td>0.029555</td>\n",
              "      <td>0.016924</td>\n",
              "      <td>107.110</td>\n",
              "      <td>43.263</td>\n",
              "      <td>191.258</td>\n",
              "      <td>...</td>\n",
              "      <td>18509.603417</td>\n",
              "      <td>17209.564571</td>\n",
              "      <td>110.037236</td>\n",
              "      <td>44.503323</td>\n",
              "      <td>3.338082</td>\n",
              "      <td>216.538139</td>\n",
              "      <td>97.294352</td>\n",
              "      <td>21067.937901</td>\n",
              "      <td>21067.937901</td>\n",
              "      <td>1_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20045120</td>\n",
              "      <td>-0.021411</td>\n",
              "      <td>-29.643486</td>\n",
              "      <td>-0.021359</td>\n",
              "      <td>-29.643561</td>\n",
              "      <td>0.000653</td>\n",
              "      <td>0.012185</td>\n",
              "      <td>5.037</td>\n",
              "      <td>3.525</td>\n",
              "      <td>276.587</td>\n",
              "      <td>...</td>\n",
              "      <td>16498.009965</td>\n",
              "      <td>18512.295208</td>\n",
              "      <td>5.738106</td>\n",
              "      <td>4.389739</td>\n",
              "      <td>4.827354</td>\n",
              "      <td>8.820318</td>\n",
              "      <td>11.444852</td>\n",
              "      <td>100.947234</td>\n",
              "      <td>100.947234</td>\n",
              "      <td>1_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33938384</td>\n",
              "      <td>-0.316375</td>\n",
              "      <td>-29.697647</td>\n",
              "      <td>-0.316375</td>\n",
              "      <td>-29.697647</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.266</td>\n",
              "      <td>346.641</td>\n",
              "      <td>...</td>\n",
              "      <td>18023.322729</td>\n",
              "      <td>18184.661968</td>\n",
              "      <td>3.031418</td>\n",
              "      <td>2.541842</td>\n",
              "      <td>6.050027</td>\n",
              "      <td>6.014593</td>\n",
              "      <td>5.140670</td>\n",
              "      <td>30.919039</td>\n",
              "      <td>30.919039</td>\n",
              "      <td>2_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7527248</td>\n",
              "      <td>-0.336528</td>\n",
              "      <td>-29.627335</td>\n",
              "      <td>-0.336527</td>\n",
              "      <td>-29.627338</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.044763</td>\n",
              "      <td>3.343</td>\n",
              "      <td>1.515</td>\n",
              "      <td>279.006</td>\n",
              "      <td>...</td>\n",
              "      <td>18128.789688</td>\n",
              "      <td>18604.884928</td>\n",
              "      <td>4.236891</td>\n",
              "      <td>2.929772</td>\n",
              "      <td>4.869573</td>\n",
              "      <td>5.937378</td>\n",
              "      <td>8.419429</td>\n",
              "      <td>49.989332</td>\n",
              "      <td>49.989332</td>\n",
              "      <td>1_1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  RA (core)  DEC (core)  RA (centroid)  DEC (centroid)      FLUX  \\\n",
              "0  24121695  -0.642227  -29.775242      -0.642316      -29.775211  0.000035   \n",
              "1  20167150  -0.390473  -29.867493      -0.390667      -29.868851  0.029555   \n",
              "2  20045120  -0.021411  -29.643486      -0.021359      -29.643561  0.000653   \n",
              "3  33938384  -0.316375  -29.697647      -0.316375      -29.697647  0.000017   \n",
              "4   7527248  -0.336528  -29.627335      -0.336527      -29.627338  0.000054   \n",
              "\n",
              "   Core frac     BMAJ    BMIN       PA  ...            x2            y2  \\\n",
              "0   0.000000    5.600   5.551  328.554  ...  19710.764566  17719.170105   \n",
              "1   0.016924  107.110  43.263  191.258  ...  18509.603417  17209.564571   \n",
              "2   0.012185    5.037   3.525  276.587  ...  16498.009965  18512.295208   \n",
              "3   0.000000    0.847   0.266  346.641  ...  18023.322729  18184.661968   \n",
              "4   0.044763    3.343   1.515  279.006  ...  18128.789688  18604.884928   \n",
              "\n",
              "   major_semia_px  minor_semia_px  pa_in_rad       width     height  \\\n",
              "0        6.264429        6.218255   5.734349   12.503792  12.461712   \n",
              "1      110.037236       44.503323   3.338082  216.538139  97.294352   \n",
              "2        5.738106        4.389739   4.827354    8.820318  11.444852   \n",
              "3        3.031418        2.541842   6.050027    6.014593   5.140670   \n",
              "4        4.236891        2.929772   4.869573    5.937378   8.419429   \n",
              "\n",
              "      area_orig  area_cropped  class_label  \n",
              "0    155.818657    155.818657          1_1  \n",
              "1  21067.937901  21067.937901          1_1  \n",
              "2    100.947234    100.947234          1_1  \n",
              "3     30.919039     30.919039          2_1  \n",
              "4     49.989332     49.989332          1_1  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------\n",
            "Starting training image preprocessing...\n",
            "\n",
            "Computing max and min pixel value in order to scale image to RGB range\n",
            "Max pixel value = 0.0065856808796525\n",
            "Removing negative noise...\n",
            "Converting to RGB...\n",
            "Removing positive noise and rescaling to 0-255 interval...\n",
            "\n",
            "Mean and stdev of the half-gaussian that best fits with noise distribution:\n",
            "mu=4.561610766868865e-14, stdev=4.5037468510513567e-07\n"
          ]
        }
      ],
      "metadata": {
        "tags": [],
        "id": "Q8IbYCwkF-5K",
        "outputId": "5cd8e5ba-49cd-49b4-d65c-65d82229f792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.cleaned_train_df[['width', 'height', 'area_orig', 'area_cropped']].describe()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.cleaned_train_df[['width', 'height', 'area_orig']].quantile([.1,.2,.3,.4,.5,.6,.7,.8,.9,.95,.98,.99,1.])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "objects_to_ignore=[20167150, 27514971]\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "show_plot = False\n",
        "# ska_dataset.generate_patches(limit=10, plot_patches=show_plot, objects_to_ignore=objects_to_ignore, source_dir=None, rgb_norm=True)\n",
        "ska_dataset.generate_patches(limit=10000, plot_patches=show_plot, objects_to_ignore=objects_to_ignore, source_dir=source_dir, rgb_norm=True)\n",
        "# ska_dataset.generate_patches(limit=1000, plot_patches=show_plot, objects_to_ignore=objects_to_ignore, source_dir='./data/training/patches', rgb_norm=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ug10Ku-OF-5Y",
        "outputId": "c3b6bed6-24a7-4f71-cbed-c4b6b8d934af",
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.split_train_val(random_state=5, val_portion=0.2, balanced=False, size=350)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fare cella per recuperare la stessa training list if resume_train=True"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# print_img(config.TRAIN_PATCHES_FOLDER, '3_16406_16729_20', show_data=True)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# # Debugging\n",
        "\n",
        "# train_patch_list = ska_dataset.train_patch_list\n",
        "# patches_folder_path=config.TRAIN_PATCHES_FOLDER\n",
        "\n",
        "# train_datagen = prep.get_anchor_gt(patches_folder_path, ['20_16396_16729_20'], backbone, pixel_mean=None)\n",
        "# image, [y_rpn_cls_true, y_rpn_reg_true], img_data_aug, _, _, patch_id = next(train_datagen)\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get FRCNN model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rpn_model, detector_model, total_model = models.get_train_model(input_shape_1=input_shape_1, input_shape_2=input_shape_2, anchor_num=config.anchor_num, pooling_regions=config.pooling_regions, num_rois=config.num_rois, num_classes=len(ska_dataset.class_list)+1, backbone=backbone, use_expander=False)\n",
        "\n",
        "rpn_model.summary()\n",
        "detector_model.summary()\n",
        "total_model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load weights"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ska_dataset.class_list"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "models.load_weigths(rpn_model, detector_model, backbone, resume_train=False, checkpoint=checkpoint)\n",
        "models.compile_models(rpn_model, detector_model, total_model, rpn_losses=[loss.rpn_loss_cls, loss.rpn_loss_regr], detector_losses=[loss.detector_loss_cls, loss.detector_loss_regr], class_list=ska_dataset.class_list)\n",
        "# models.compile_models(rpn_model, detector_model, total_model, rpn_losses=[loss.rpn_loss_cls, loss.rpn_loss_regr], detector_losses=[loss.categorical_focal_loss([.25, .25, .25, .25, .25, .25], 2.), loss.detector_loss_regr], class_list=ska_dataset.class_list)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Specifically checking backbone weights\n",
        "\n",
        "# total_model.weights[24:25][0][0][0][0]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Check that all of the pretrained weights have been loaded.\n",
        "import numpy as np\n",
        "for i, j in zip(total_model.weights, rpn_model.weights): \n",
        "    # print(i,j)\n",
        "    assert np.allclose(i,j), 'Weights don\\'t match!'"
      ],
      "outputs": [],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- errore \"Exception: 'a' cannot be empty unless no samples are taken\" quando nel sampling ci sono meno di 4 roi\n",
        "- errore \"None type object is not iterable\" dovuto al max(IoUs) quando calc_iou torna None, None, None, None\n",
        "- patch di debug 1550_16376_16779_100\n",
        "- capire il parametro classifier_regr_std in che modo influenza il training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- provare normalizzazione valori immagini di input\n",
        "- provare a far passare più roi anzichè 4"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Generating validation model for validation step at epoch's end\n",
        "rpn_model_eval, detector_model_eval, total_model_eval = models.get_eval_model(input_shape_1=input_shape_1, input_shape_2=input_shape_2, input_shape_fmap=None, anchor_num=config.anchor_num, pooling_regions=config.pooling_regions, num_rois=config.num_rois, num_classes=len(ska_dataset.class_list)+1, backbone=backbone, use_expander=False)\n",
        "\n",
        "rpn_model_eval.summary()\n",
        "detector_model_eval.summary()\n",
        "total_model_eval.summary()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from src.train import *\n",
        "\n",
        "# train_frcnn(rpn_model, detector_model, total_model, ['2_16396_16729_20'], val_patch_list, ska_dataset.class_list, num_epochs=100, patches_folder_path=config.TRAIN_PATCHES_FOLDER, backbone=backbone, resume_train=True)\n",
        "train_frcnn(rpn_model, detector_model, total_model, ska_dataset.train_patch_list, rpn_model_eval, detector_model_eval, total_model_eval, ska_dataset.val_patch_list, ska_dataset.class_list, num_epochs=80, patches_folder_path=config.TRAIN_PATCHES_FOLDER, backbone=backbone, resume_train=False)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rpn_model_eval, detector_model_eval, total_model_eval = models.get_eval_model(input_shape_1=input_shape_1, input_shape_2=input_shape_2, input_shape_fmap=None, anchor_num=config.anchor_num, pooling_regions=config.pooling_regions, num_rois=config.num_rois, num_classes=len(ska_dataset.class_list)+1, backbone=backbone, use_expander=False)\n",
        "\n",
        "rpn_model_eval.summary()\n",
        "detector_model_eval.summary()\n",
        "total_model_eval.summary()"
      ],
      "outputs": [],
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Models used for mAP eval\n",
        "# cp = '95_frcnn_baseline_44.h5'\n",
        "cp = 'map_4_frcnn_baseline_16.h5'\n",
        "models.load_weigths(rpn_model_eval, detector_model_eval, backbone, checkpoint=cp)\n",
        "models.compile_models(rpn_model_eval, detector_model_eval, total_model_eval, rpn_losses=[loss.rpn_loss_cls, loss.rpn_loss_regr], detector_losses=[loss.detector_loss_cls, loss.detector_loss_regr], class_list=ska_dataset.class_list)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "patch_id = ['15768_16646_17719_20']#['2_16396_16729_20']#, '3_16406_16729_20']\n",
        "patch_id = ska_dataset.val_patch_list\n",
        "# print(patch_id)\n",
        "# gt = pd.read_pickle(f'{config.TRAIN_PATCHES_FOLDER}/{patch_id[0]}/{patch_id[0]}.pkl')\n",
        "# display(gt['class_label'])\n",
        "\n",
        "preds, mAP, mPrecision = evaluate_model(rpn_model_eval, detector_model_eval, backbone, patch_id, ska_dataset.class_list, map_threshold=.1, acceptance_treshold=.5, save_eval_results=True)\n",
        "# preds, mAP, prec, recall = evaluate_model(rpn_model_eval, detector_model_eval, backbone, patch_id, ska_dataset.class_list, metric_threshold=.5, acceptance_treshold=.5)"
      ],
      "outputs": [],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "anch = pd.read_pickle(f'{config.EVAL_RESULTS}/15768_16646_17719_20/15768_16646_17719_20.pkl')\n",
        "display(anch)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "anch['width'] = anch['x2s'] - anch['x1s']\n",
        "anch['heght'] = anch['y2s'] - anch['y1s']"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "anch.describe() "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "patch = '15835_17316_17719_20'\n",
        "\n",
        "# print_img(config.TRAIN_PATCHES_FOLDER, patch)\n",
        "\n",
        "print_img(config.TRAIN_PATCHES_FOLDER, patch, config.EVAL_RESULTS, show_data=False)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO - 20210508:\n",
        "- [X] troncamento rumore a 1e-6 tramite half gaussian\n",
        "\n",
        "TODO - 20210605:\n",
        "- [X] modificare RPNNet in modo che dia in output anche la backbone - Lorenzo\n",
        "- [X] scrivere bene training loop: salvare le loss in un df su disco + salvare pesi modello ad ogni giro (Lorenzo - finire di debuggare)\n",
        "\n",
        "TODO - 20210620:\n",
        "- [x] implementare mAP in una funzione che prende come parametro un modello o i suoi pesi\n",
        "- [x] implementare resNet50\n",
        "- [x] implementare predicted rois - Lorenzo\n",
        "- [X] implementare plot loss training - Lorenzo\n",
        "- [X] finire classe datasetv2 - Alice\n",
        "- [X] check se su colab le performance sono migliori - Lorenzo\n",
        "\n",
        "TODO - 20210627\n",
        "- [X] split dataset su combinazioni classi - Alice\n",
        "- [x] provare campionamento random patch ed osservare le due distribuzioni - Alice\n",
        "\n",
        "TODO - 20210703\n",
        "- [x] sistemare salvataggio loss training loop - Lorenzo\n",
        "- [x] Riscalare immagini tra 0-255 - Alice\n",
        "- [x] capire se passare tre immagini diverse come input\n",
        "- [x] usare media vgg16 per zero-centering - Alice\n",
        "\n",
        "TODO - 20210705\n",
        "- [x] sistemare nomi funzioni dataset per trasformazione rgb\n",
        "\n",
        "TODO - 20210711\n",
        "- [x] rifattorizzare classe dataset spostando nel costruttore i metodi che calcolano i suoi attributi - Lorenzo\n",
        "- [x] chek valori pixel in input per resnet\n",
        "- [x] fare funzione per plottare le predictions\n",
        "- [ ] trainare tutto su colab\n",
        "\n",
        "TODO - 20210714\n",
        "- [x] ragionare su come scalare le immagini fra 0 e 1, attualmente hanno tanti valori schiacciati a 0 e il massimo su tutto il train a a 0.4\n",
        "\n",
        "TODO - 20210717\n",
        "- [ ] Ablation study: provare a rimuovere stage4 nella resnet - se c'è tempo\n",
        "- [x] Provare con nostra pixel_mean e con vgg16 pixel_mean -> per il momento abbiamo scartato la prima opzione\n",
        "- [x] Fare qualche analisi di distribuzione delle classi/dim box del dataset - Alice\n",
        "- [x] Aggiungere normalizzazione dopo zero centering per resNet50, sulla base del range globale dell'immagine di training\n",
        "- [x] Provare pulizia dataset originale sulla base del rumore/flusso - Alice\n",
        "- [ ] Cambiare nomi di tutto - alla fine\n",
        "- [x] implementare zero-centering su volare medio RGB delle nostre patch\n",
        "- [x] Funzione che trova l'ultimo checkpoint in colab prima del load_weights - Lorenzo\n",
        "\n",
        "TODO - 20210801\n",
        "- [x] Debuggare training baseline 8 e 16 - L\n",
        "- [x] Finire prove pulizia dataseet noise variando k - A\n",
        "\n",
        "TODO - 20210904\n",
        "- [ ] Provare NMS per rimuovere oggetti crowded\n",
        "- [ ] In evaluate model eliminare le box con una delle due dim a 0 e quelle che escono dalla patch"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Summary\n",
        "    - riassunto progetto\n",
        "2.  Background\n",
        "    - SoTA + teoria di base\n",
        "3.  System Description\n",
        "    - descrizione dei nostri modelli e dei loro componenti (moduli)\n",
        "4.  Experimental setup and results\n",
        "    - dataset pre processing\n",
        "    - training environment\n",
        "    - metrics\n",
        "    - results\n",
        "5.  Results and error analysis\n",
        "6.  Discussion"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "loss_history = np.load(f\"./model/{backbone}/loss_history.npy\")\n",
        "print(loss_history.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 5)\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "loss_history"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_loss(loss_history[:])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "scores_history = np.load(f\"./model/{backbone}/scores_history.npy\")\n",
        "print(scores_history.shape)\n",
        "plot_scores(scores_history[:])\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.convolve(loss_history[1], np.ones(10), 'valid') / 10"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n",
        "\n",
        "lsma_0 = moving_average(loss_history[100:,2], 200)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, len(lsma_0)), lsma_0, 'r')\n",
        "plt.title('rpn cls')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelli da trainare:\n",
        "epoch lenght = 200\n",
        "- baseline_16: patch 50 -> 100, [8,16,32,64]-[1:1], 16roi, limit=4000, 10k epoche, focal_loss, norm: media, no bilanciamento dataset, rgbNorm=True - A\n",
        "- baseline_16: patch 50 -> 100, [8,16,32,64]-[1:1], 16roi, limit=4000, 10k epoche, NO focal_loss, norm: media, no bilanciamento dataset, rgbNorm=True - A\n",
        "\n",
        "- baseline_16: patch 20->100, [4,8,16,24,32,64]-[1:1,1:2,2:1], 16roi, limit=4000, 10k epoche, no focal_loss, norm: media, no bilanciamento dataset, rgbNorm=True - L\n",
        "- baseline_16: patch 20->100, [4,8,16,24,32,64]-[1:1,1:2,2:1], 16roi, limit=4000, 10k epoche, focal_loss, norm: media, no bilanciamento dataset, rgbNorm=True- L\n",
        "\n",
        "\n",
        "- baseline_44: patch 20->100, [4,8,16,24,32,64]-[1:1,1:2,2:1], 16roi, limit=4000, 10k epoche, no focal_loss, norm: media, no bilanciamento dataset, rgbNorm=True - L\n",
        "- baseline_44: patch 20->100, [4,8,16,24,32,64]-[1:1,1:2,2:1], 16roi, limit=4000, 10k epoche, focal_loss, norm: media, no bilanciamento dataset, rgbNorm=True - L\n",
        "\n",
        "- vgg16: 100 -> 600, [32,64,128,256,512]-[1:1,1:2,2:1], 16roi, limit=4000, 10k epoche, no focal_loss, norm: media, no bilanciamento dataset, rgbNorm=True"
      ],
      "metadata": {}
    }
  ]
}