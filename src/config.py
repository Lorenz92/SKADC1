import os
import math

# Generic config
RANDOM_SEED = 42
DATA_SUBSET = 1
DOWNLOAD_FOLDER = 'data/training'
DATA_FOLDER = os.path.join(os.getcwd(), "data")
TRAIN_DATA_FOLDER = os.path.join(DATA_FOLDER, "training")
TRAIN_PATCHES_FOLDER = os.path.join(TRAIN_DATA_FOLDER, "patches")
TRAIN_SET_PATH_CLEANED = os.path.join(TRAIN_DATA_FOLDER, "B1_training_clean_SKA.txt") #TODO: fix this
TRAIN_SET_PATH = os.path.join(TRAIN_DATA_FOLDER, "B1_training_SKA.txt") #TODO: fix this

MODEL_WEIGHTS = os.path.join(os.getcwd(), "model")

required_files = [
    {
        "file_name": "B1_training_SKA.txt",
        "url": "https://owncloud.ia2.inaf.it/index.php/s/iTOVkIL6EfXkcdR/download" #54Mb
    },
    # {
    #     "file_name": "PrimaryBeam_B1.fits",
    #     "url": "https://owncloud.ia2.inaf.it/index.php/s/ZbaSDe7zGBYgxL1/download" #300Kb
    # },
    # {
    #     "file_name": "SynthesBeam_B1.fits",
    #     "url": "https://owncloud.ia2.inaf.it/index.php/s/cwzf1BO2pyg9TVv/download" #4Gb
    # },
    {
        "file_name": "560Mhz_1000h.fits",
        "url": "https://owncloud.ia2.inaf.it/index.php/s/hbasFhd4YILNkCr/download" #4Gb
    },
        {
        "file_name": "B5_training_SKA.txt",
        "url": "https://owncloud.ia2.inaf.it/index.php/s/Y5CIa5V3QiBu1M1/download" #54Mb
    },
    {
        "file_name": "9200Mhz_1000h.fits",
        "url":"https://owncloud.ia2.inaf.it/index.php/s/nK8Pqf3XIaXFuKD/download"
    }
]

#TODO: convert the following in class
'''
class Config:

	def __init__(self):
'''
# Print the process or not
verbose = True

# Name of base network
network = 'vgg'

# Setting for data augmentation
use_horizontal_flips = True
use_vertical_flips = True
rot_90 = True

# Anchor box scales
# Note that if im_size is smaller, anchor_box_scales should be scaled
# Original anchor_box_scales in the paper is [128, 256, 512]
anchor_box_scales = [1, 2, 4, 8, 16, 32] 
# anchor_box_scales = [32, 64, 128, 256, 512]

# Anchor box ratios
# anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]
anchor_box_ratios = [[1, .5], [1, 1], [1, 2]]

anchor_num = len(anchor_box_ratios)*len(anchor_box_scales)

# Size to resize the smallest side of the image
# Original setting in paper is 600. Set to 300 in here to save training time
im_size = 300
in_out_img_size_ratio = 16

# image channel-wise mean to subtract
img_channel_mean =  [3.8131893e-07] #mean value of all patches
img_channel_max = 0.006585681
img_channel_min = 0.0
#img_channel_mean =  [2.1317146e-06] #mean value of all patches
img_scaling_factor = 1.0

# number of ROIs at once
num_rois = 4

# stride at the RPN (this depends on the network configuration)
rpn_stride = 16

balanced_classes = False

# scaling the stdev
std_scaling = 4.0
classifier_regr_std = [8.0, 8.0, 4.0, 4.0]

# overlaps for RPN
rpn_min_overlap = 0.3
rpn_max_overlap = 0.7

# overlaps for classifier ROIs
classifier_min_overlap = 0.1
classifier_max_overlap = 0.5

# placeholder for the class mapping, automatically generated by the parser
class_mapping = None

model_path = None

use_bg = False